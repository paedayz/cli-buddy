import warnings
from langchain._api import LangChainDeprecationWarning
warnings.simplefilter("ignore", category=LangChainDeprecationWarning)

import os
import sys
from dotenv import load_dotenv
from langchain_community.chat_models import ChatOpenAI
from langchain.schema import HumanMessage

def run_repl(llm):
    print("ðŸ‘‹ Welcome to Buddy CLI! Type 'exit' or 'quit' to leave.\n")
    while True:
        try:
            prompt = input("buddy> ").strip()
            if prompt.lower() in {"exit", "quit"}:
                print("ðŸ‘‹ Bye!")
                break
            if not prompt:
                continue
            response = llm([HumanMessage(content=prompt)])
            print(f"ðŸ¤– Buddy: {response.content}\n")
        except KeyboardInterrupt:
            print("\nðŸ‘‹ Bye!")
            break

def main():
    load_dotenv()
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)

    user_prompt = " ".join(sys.argv[1:])

    if not user_prompt:
        # No arguments â†’ enter REPL mode
        run_repl(llm)
    else:
        # Run single-shot command
        response = llm([HumanMessage(content=user_prompt)])
        print(f"\nðŸ¤– Buddy: {response.content}")

